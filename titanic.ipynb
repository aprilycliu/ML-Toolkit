{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploratory Data Analysis:\n",
    "Getting insight into the dataset is one of the most important things. First step should be to look at the properties of data which gives us clarity. It can give us a meaningful understanding and relationship of data with the target.\n",
    "\n",
    "2. Data Processing:\n",
    "Data Cleaning: Dealing with missing value, and Feature Engineering by Creating new features and Enconding. Finally to build Data processing pipeline in this step.\n",
    "\n",
    "3. Modeling:\n",
    "The third step is to properly train a model which does not overfit on the seen data. Used cross validation on 10 folds to meausure the performance on train data.\n",
    "\n",
    "4. Hypter parameter tunning:\n",
    "Tuning algorithm and model parameters contribute to significant improvement in the score. \n",
    "\n",
    "5. Ensembling:\n",
    "The last step is all about creating a strong model from a large number of weak models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "train_data.head()\n",
    "\n",
    "train_copy = train_data.copy()\n",
    "test_copy = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.plotting generate a fast and convenient report with visualization, correalation, missing values.\n",
    "Oberseve each attribute for the following feature engineering work\n",
    "\n",
    "*Training set have missing values in Age, Cabin and Embarked columns.\n",
    "\n",
    "*Test set have missing values in Age, Cabin and Fare columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pp.ProfileReport(train_data)\n",
    "profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Age distribution seems to be a gaussian distribution. We can notice that Age distribution are not the same in the survived and not survived subpopulation: \n",
    "#Those who are between 60 and 80 are less likely to survive, and childrens and young passengers have higher chances of survival.\n",
    "#Transforming the age feature into categories seems better than using the age of each person because some there is some age categories that have high or less chance of surviving.\n",
    "g = sns.FacetGrid(train_copy, col='Survived')\n",
    "g = g.map(sns.histplot, \"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1 value of Fare attribute is missing in test and only 2 values of Embarked attribute are missing in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                Name   Sex   Age  SibSp  Parch Ticket  \\\n",
       "152         1044       3  Storey, Mr. Thomas  male  60.5      0      0   3701   \n",
       "\n",
       "     Fare Cabin Embarked  \n",
       "152   NaN   NaN        S  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_copy[test_copy['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare distribution is very skewed and might result in badbehaviour in our model. Transforming it into log seems like a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(train_copy, col='Survived')\n",
    "g = g.map(sns.histplot, \"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the name attribute we can extract the title and analyse it better. \n",
    "We can extract family names also but that would take too much time so I am gonna stick to the title only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deck  Pclass\n",
       "A     1          15\n",
       "B     1          47\n",
       "C     1          59\n",
       "D     1          29\n",
       "      2           4\n",
       "E     1          25\n",
       "      2           4\n",
       "      3           3\n",
       "F     2           8\n",
       "      3           5\n",
       "G     3           4\n",
       "T     1           1\n",
       "X     1          40\n",
       "      2         168\n",
       "      3         479\n",
       "Name: deck, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Its true that most of Cabin attribute are missing values but we can't drop this feature because some of the cabins have more survival rate than others, \n",
    "#for example these who are close to surface.\n",
    "#It seems like the first letter of the Cabin values are the decks in which the cabins are located. So we will change the cabin attribute with a deck attribute and explore further this new feature\n",
    "\n",
    "train_data[\"deck\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in train_data['Cabin'] ])\n",
    "test_data[\"deck\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in test_data['Cabin'] ])\n",
    "\n",
    "train_data.groupby(['deck','Pclass'])['deck'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['Title'] = train_copy['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       1.000000\n",
      "Fare           0.257307\n",
      "Parch          0.081629\n",
      "PassengerId   -0.005007\n",
      "SibSp         -0.035322\n",
      "Age           -0.077221\n",
      "Pclass        -0.338481\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def corr(x):\n",
    "    corr_matrix = x.corr()\n",
    "    c= corr_matrix[\"Survived\"].sort_values(ascending=False)\n",
    "    print(c)\n",
    "corr(train_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Missing Data: \n",
    "Age > replace the missing values with the media age for each class, for both male and female passengers.\n",
    "\n",
    "Fare > we have only 1 missing value. We will fill it with the median 3rd class passangers that have no family with them\n",
    "\n",
    "Embarked > we will use the most Frequent which is S\n",
    "\n",
    "Cabin > we will deal with it in the feature engineering section because we are going to create a new attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.med_fare_ = X.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "        self.most_freq_embarked = X.Embarked.value_counts().index[0]\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        #replacing missing values of Age with median Age for each class. 1 value for each Sex.\n",
    "        X.Age = X.groupby(['Sex', 'Pclass'])['Age'].apply(lambda z: z.fillna(z.median()))\n",
    "        # 1 only missing value for Fare. A Man in the third class with no family\n",
    "        X.Fare = X.Fare.fillna(self.med_fare_)\n",
    "        # filling Embarked with the most frequent \n",
    "        X.Embarked = X.Embarked.fillna(self.most_freq_embarked)\n",
    "        \n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new features\n",
    "In this section we will transform existing attribute and create new ones:\n",
    "\n",
    "Parch and SibSp > combine to create a Relative on board feature.\n",
    "Using the Relative On board feature we will create a family attribute which consists of:\n",
    "(Alone if the passenger has no relatives on board\n",
    "Small if he have 1 or 2 family members on board\n",
    "Medium if he have 3, 4 or 5 family members\n",
    "Large if he has more than 6)\n",
    "\n",
    "Cabin > we will create a deack attribute by extracting the first letter of the cabin name for each passenger.\n",
    "\n",
    "Age > transform from continuous data into and attribute with 8 categories.\n",
    "\n",
    "Fare > Applying log will reduce skewness distribution\n",
    "\n",
    "Ticket ID > replaced by ticket frequency\n",
    "\n",
    "Title > extracted from Name and create IsMarried Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_engineering(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # combining Sibsp and Parch to create relative on board then creating the family attribute\n",
    "        X[\"RelativesOnboard\"] = X[\"SibSp\"] + X[\"Parch\"]\n",
    "        X['Family'] = X['RelativesOnboard'].map({0: 'Alone', 1: 'Small', 2: 'Small', 3: 'Medium', 4: 'Medium', 5: 'Medium', 6: 'Large', 7: 'Large', 10: 'Large'})\n",
    "        # extracting the first letter of each cabin to create deck attribute\n",
    "        X[\"Deck\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in X['Cabin'] ])  \n",
    "        # regrouping deck catergories\n",
    "        X['Deck'] = X['Deck'].replace(['T', 'A', 'B', 'C'], 'ABC')\n",
    "        X['Deck'] = X['Deck'].replace(['D', 'E'], 'DE')\n",
    "        X['Deck'] = X['Deck'].replace(['F', 'G'], 'FG')\n",
    "        # we will transform the Age from continuous data into and attribute with 14 category.\n",
    "        X[\"Age\"] = pd.cut(X[\"Age\"],\n",
    "                               bins=[0., 5.0, 15.0, 25.0, 30.0, 40.0,50.0,60.0, np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5,6,7,8])\n",
    "        # For Fare, Applying will reduce skewness distribution\n",
    "        X[\"Fare\"] = X[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "        # Replace ticket ID by ticket frequency\n",
    "        X['Ticket_Frequency'] = X.groupby('Ticket')['Ticket'].transform('count')\n",
    "        # Extract title attribute from Name and create IsMarried Attribute\n",
    "        X['Title'] = X['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "        X['Is_Married'] = 0\n",
    "        X['Is_Married'].loc[X['Title'] == 'Mrs'] = 1\n",
    "        X['Title'] = X['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "        X['Title'] = X['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encodeing on the following features:\n",
    "\n",
    "Age, Fare, Embarked, Sex, Title, Family, Title, RelativesOnboard, Deck.\n",
    "\n",
    "And use OneHotEncoding on the folliwing featues:\n",
    "\n",
    "Pclass, Sex, Deck, Family, Title, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.le = LabelEncoder()\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        #label encoding\n",
    "        for i in ['Age', 'Fare', 'Embarked', 'Sex', 'Title', 'Family', 'Title', 'RelativesOnboard', 'Deck']:\n",
    "            X[i] = self.le.fit_transform(X[i])\n",
    "        #OneHotEncoding\n",
    "        encoded_features = []\n",
    "        for cat in ['Deck', 'Age','Pclass', 'Sex', 'Title','Embarked','Family','RelativesOnboard']:\n",
    "            encoded_feat = self.ohe.fit_transform(X[cat].values.reshape(-1, 1)).toarray()\n",
    "            n = X[cat].nunique()\n",
    "            cols = ['{}_{}'.format(cat, n) for n in range(1, n + 1)]\n",
    "            encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "            encoded_df.index = X.index\n",
    "            encoded_features.append(encoded_df)\n",
    "        X = pd.concat([X, *encoded_features[:8]], axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is used after cleaning and feature engineering to drop unnecessary columns\n",
    "class Columns_drop(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.drop(self.attribute_names, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = [ 'RelativesOnboard','Age', 'Sex','Deck', 'Family', \n",
    "                   'Embarked', 'PassengerId', 'Pclass', 'Name', 'Ticket','Cabin','Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline = Pipeline([\n",
    "    ('Filling missing values', Imputer()),\n",
    "    ('Feature Engineering', feature_engineering()),\n",
    "    ('Encoding', encoding()),\n",
    "    ('dropping useless columns', Columns_drop(dropped_columns) ),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived              1.000000\n",
      "Sex_1                 0.543351\n",
      "Title_3               0.540769\n",
      "Is_Married            0.339040\n",
      "Fare                  0.333943\n",
      "Pclass_1              0.285904\n",
      "Family_4              0.238059\n",
      "Deck_2                0.213430\n",
      "Deck_1                0.202551\n",
      "Embarked_1            0.168240\n",
      "RelativesOnboard_2    0.163157\n",
      "Age_1                 0.150304\n",
      "RelativesOnboard_3    0.143869\n",
      "RelativesOnboard_4    0.128347\n",
      "Pclass_2              0.093349\n",
      "Title_2               0.085221\n",
      "Parch                 0.081629\n",
      "Age_5                 0.068219\n",
      "Deck_3                0.058617\n",
      "Ticket_Frequency      0.038247\n",
      "Age_2                 0.034183\n",
      "Family_3              0.014687\n",
      "Age_7                 0.009569\n",
      "Embarked_2            0.003650\n",
      "Age_4                 0.002193\n",
      "Age_6                -0.000079\n",
      "RelativesOnboard_7   -0.012134\n",
      "Title_1              -0.031348\n",
      "SibSp                -0.035322\n",
      "RelativesOnboard_5   -0.049466\n",
      "Age_8                -0.051224\n",
      "RelativesOnboard_8   -0.064988\n",
      "RelativesOnboard_9   -0.070234\n",
      "Family_2             -0.078203\n",
      "RelativesOnboard_6   -0.080968\n",
      "Age_3                -0.126765\n",
      "Embarked_3           -0.149683\n",
      "Family_1             -0.203367\n",
      "RelativesOnboard_1   -0.203367\n",
      "Deck_4               -0.316912\n",
      "Pclass_3             -0.322308\n",
      "Title                -0.402510\n",
      "Sex_2                -0.543351\n",
      "Title_4              -0.549199\n",
      "Name: Survived, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train= train_data.copy()\n",
    "X_test = test_data.copy()\n",
    "\n",
    "X_train = processing_pipeline.fit_transform(X_train)\n",
    "corr(X_train)\n",
    "X_train = X_train.drop('Survived',axis=1 )\n",
    "y_train = train_data['Survived']\n",
    "X_test = processing_pipeline.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 43), (418, 43), (891,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating models and making a choice\n",
    "\n",
    "In this section we evaluate the performance of some well known models on the data and chose those who have a good accuracy. We will cross validation on 10 folds to meausure the performance on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValerrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.784677</td>\n",
       "      <td>0.042720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.813741</td>\n",
       "      <td>0.024778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.817050</td>\n",
       "      <td>0.040450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.832842</td>\n",
       "      <td>0.040291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.800334</td>\n",
       "      <td>0.039011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.828348</td>\n",
       "      <td>0.037613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.823828</td>\n",
       "      <td>0.039609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Algorithm  CrossValMeans  CrossValerrors\n",
       "0               SVC       0.784677        0.042720\n",
       "1      DecisionTree       0.813741        0.024778\n",
       "2      RandomForest       0.817050        0.040450\n",
       "3  GradientBoosting       0.832842        0.040291\n",
       "4        ExtraTrees       0.800334        0.039011\n",
       "5               XGB       0.828348        0.037613\n",
       "6              LGBM       0.823828        0.039609"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10)\n",
    "random_state = 42\n",
    "classifiers = []\n",
    "classifiers.append(SVC(random_state=random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier())\n",
    "classifiers.append(XGBClassifier())\n",
    "classifiers.append(LGBMClassifier())\n",
    "cv_results = []\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n",
    "    \n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame({\"Algorithm\":[\"SVC\",\"DecisionTree\",\"RandomForest\",\"GradientBoosting\",\"ExtraTrees\",\"XGB\",'LGBM'],\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std})\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypter parameter tunning and combining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [ 20 ,'auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "rf_param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8372615039281706"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest Hyper parameter tuning\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#fitting\n",
    "Grid_s_rf = GridSearchCV(rf, param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = True)\n",
    "Grid_s_rf.fit(X_train,y_train)\n",
    "RFC_best = Grid_s_rf.best_estimator_\n",
    "\n",
    "# Best score\n",
    "Grid_s_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of boosting stages to perform\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [ 20 ,'auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 20, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,  10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# The function to measure the quality of a split\n",
    "# Create the random grid\n",
    "gb_param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8249158249158249"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "#fitting\n",
    "Grid_s_gb = GridSearchCV(gbc,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "Grid_s_gb.fit(X_train,y_train)\n",
    "GBC_best = Grid_s_gb.best_estimator_\n",
    "\n",
    "# Best score\n",
    "Grid_s_gb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(5, 20, num = 3)]\n",
    "min_child_weight = [5,6,7]\n",
    "eta = [.3, .2, .1, .05, .01, .005]\n",
    "\n",
    "XGB_param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'eta': eta,\n",
    "               'min_child_weight': min_child_weight,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 486 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4860 out of 4860 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8406285072951739"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "\n",
    "Grid_s_XGB = GridSearchCV(XGB, param_grid = XGB_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = True)\n",
    "Grid_s_XGB.fit(X_train,y_train)\n",
    "XGB_best = Grid_s_XGB.best_estimator_\n",
    "\n",
    "Grid_s_XGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9214365881032548\n"
     ]
    }
   ],
   "source": [
    "#Combining 2 models\n",
    "votingC = VotingClassifier(estimators=[('lg', lg),('xgb',xgb)], voting='soft', n_jobs=-1)\n",
    "votingC = votingC.fit(X_train, y_train)\n",
    "print('Score: ', votingC.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8799102132435466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "print('Score: ', xgb.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8249158249158249\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "rf.fit(X_train,y_train)\n",
    "print('Score: ', rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9427609427609428\n"
     ]
    }
   ],
   "source": [
    "lg = LGBMClassifier()\n",
    "lg.fit(X_train,y_train)\n",
    "print('Score: ', lg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_2.predict(X_test)\n",
    "submission = pd.DataFrame({'PassengerId': test_data.PassengerId,\n",
    "                           'Survived': predictions})\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_X_train, s_X_test, s_y_train, s_y_test = train_test_split(X_train, y_train, train_size=0.75, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8608305274971941\n"
     ]
    }
   ],
   "source": [
    "model_1 = XGBClassifier(n_estimators = 10000, learning_rate = 0.5, use_label_encoder=False, eval_metric = 'logloss')\n",
    "model_1.fit(s_X_train, s_y_train, early_stopping_rounds = 9, eval_set = [(s_X_test, s_y_test)], verbose = False)\n",
    "print('Score: ', model_1.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8473625140291807\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators = 550, max_depth = 6, random_state = 1)\n",
    "model_2.fit(s_X_train, s_y_train)\n",
    "print('Score: ', model_2.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
